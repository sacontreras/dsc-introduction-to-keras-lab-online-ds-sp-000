{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab you'll once again build a neural network, but this time you will be using Keras to do a lot of the heavy lifting.\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Build a neural network using Keras \n",
    "- Evaluate performance of a neural network using Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "\n",
    "We'll start by importing all of the required packages and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "In this lab you will be classifying bank complaints available in the `'Bank_complaints.csv'` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 2 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Product                       60000 non-null  object\n",
      " 1   Consumer complaint narrative  60000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 937.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "\n",
    "# Inspect data\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, your task is to categorize banking complaints into various predefined categories. Preview what these categories are and what percent of the complaints each accounts for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Student loan                   11404\n",
       "Credit card                     9540\n",
       "Consumer Loan                   9474\n",
       "Mortgage                        8332\n",
       "Bank account or service         8309\n",
       "Credit reporting                6864\n",
       "Checking or savings account     6077\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df.Product.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Student loan                   0.190067\n",
       "Credit card                    0.159000\n",
       "Consumer Loan                  0.157900\n",
       "Mortgage                       0.138867\n",
       "Bank account or service        0.138483\n",
       "Credit reporting               0.114400\n",
       "Checking or savings account    0.101283\n",
       "Name: Product, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Product.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Before we build our neural network, we need to do several preprocessing steps. First, we will create word vector counts (a bag of words type representation) of our complaints text. Next, we will change the category labels to integers. Finally, we will perform our usual train-test split before building and training our neural network using Keras. With that, let's start munging our data! \n",
    "\n",
    "## One-hot encoding of the complaints\n",
    "\n",
    "Our first step again is to transform our textual data into a numerical representation. As we saw in some of our previous lessons on NLP, there are many ways to do this. Here, we'll use the `Tokenizer()` class from the `preprocessing.text` sub-module of the Keras package.   \n",
    "\n",
    "As with our previous work using NLTK, this will transform our text complaints into word vectors. (Note that the method of creating a vector is different from our previous work with NLTK; as you'll see, word order will be preserved as opposed to a bag of words representation). In the below code, we'll only keep the 2,000 most common words and use one-hot encoding. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchar_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moov_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdocument_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Text tokenization utility class.\n",
       "\n",
       "This class allows to vectorize a text corpus, by turning each\n",
       "text into either a sequence of integers (each integer being the index\n",
       "of a token in a dictionary) or into a vector where the coefficient\n",
       "for each token could be binary, based on word count, based on tf-idf...\n",
       "\n",
       "# Arguments\n",
       "    num_words: the maximum number of words to keep, based\n",
       "        on word frequency. Only the most common `num_words-1` words will\n",
       "        be kept.\n",
       "    filters: a string where each element is a character that will be\n",
       "        filtered from the texts. The default is all punctuation, plus\n",
       "        tabs and line breaks, minus the `'` character.\n",
       "    lower: boolean. Whether to convert the texts to lowercase.\n",
       "    split: str. Separator for word splitting.\n",
       "    char_level: if True, every character will be treated as a token.\n",
       "    oov_token: if given, it will be added to word_index and used to\n",
       "        replace out-of-vocabulary words during text_to_sequence calls\n",
       "\n",
       "By default, all punctuation is removed, turning the texts into\n",
       "space-separated sequences of words\n",
       "(words maybe include the `'` character). These sequences are then\n",
       "split into lists of tokens. They will then be indexed or vectorized.\n",
       "\n",
       "`0` is a reserved index that won't be assigned to any word.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.pyenv/versions/anaconda3-2020.02/envs/learn-env/lib/python3.8/site-packages/keras_preprocessing/text.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# As a quick preliminary, briefly review the docstring for keras.preprocessing.text.Tokenizer\n",
    "Tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences type: <class 'list'>\n",
      "one_hot_results type: <class 'numpy.ndarray'>\n",
      "Found 50110 unique tokens.\n",
      "Dimensions of our coded results: (60000, 2000)\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take about thirty seconds to run\n",
    "\n",
    "# Raw text complaints\n",
    "complaints = df['Consumer complaint narrative'] \n",
    "\n",
    "# Initialize a tokenizer \n",
    "tokenizer = Tokenizer(num_words=2000) \n",
    "\n",
    "# Fit it to the complaints\n",
    "tokenizer.fit_on_texts(complaints) \n",
    "\n",
    "# Generate sequences\n",
    "sequences = tokenizer.texts_to_sequences(complaints) \n",
    "print('sequences type:', type(sequences))\n",
    "\n",
    "# Similar to sequences, but returns a numpy array\n",
    "one_hot_results= tokenizer.texts_to_matrix(complaints, mode='binary') \n",
    "print('one_hot_results type:', type(one_hot_results))\n",
    "\n",
    "# Useful if we wish to decode (more explanation below)\n",
    "word_index = tokenizer.word_index \n",
    "\n",
    "# Tokens are the number of unique words across the corpus\n",
    "print('Found %s unique tokens.' % len(word_index)) \n",
    "\n",
    "# Our coded data\n",
    "print('Dimensions of our coded results:', np.shape(one_hot_results)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding Word Vectors \n",
    "\n",
    "As a note, you can also decode these vectorized representations of the reviews. The `word_index` variable, defined above, stores the mapping from the label number to the actual word. Somewhat tediously, we can turn this dictionary inside out and map it back to our word vectors, giving us roughly the original complaint back. (As you'll see, the text won't be identical as we limited ourselves to top 2000 words.)\n",
    "\n",
    "## Python Review / Mini Challenge\n",
    "\n",
    "While a bit tangential to our main topic of interest, we need to reverse our current dictionary `word_index` which maps words from our corpus to integers. In decoding our `one_hot_results`, we will need to create a dictionary of these integers to the original words. Below, take the `word_index` dictionary object and change the orientation so that the values are keys and the keys values. In other words, you are transforming something of the form {A:1, B:2, C:3} to {1:A, 2:B, 3:C}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxx: 1\n",
      "the: 2\n",
      "i: 3\n",
      "to: 4\n",
      "and: 5\n",
      "my: 6\n",
      "a: 7\n",
      "that: 8\n",
      "of: 9\n",
      "was: 10\n",
      "in: 11\n",
      "they: 12\n",
      "on: 13\n",
      "for: 14\n",
      "have: 15\n",
      "not: 16\n",
      "me: 17\n",
      "this: 18\n",
      "is: 19\n",
      "with: 20\n"
     ]
    }
   ],
   "source": [
    "# let's just have a look at the the first 20 items...\n",
    "i = 0\n",
    "for t in word_index.items():\n",
    "    if i < 20:\n",
    "        print(f\"{t[0]}: {t[1]}\")\n",
    "        i += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: xxxx\n",
      "2: the\n",
      "3: i\n",
      "4: to\n",
      "5: and\n",
      "6: my\n",
      "7: a\n",
      "8: that\n",
      "9: of\n",
      "10: was\n",
      "11: in\n",
      "12: they\n",
      "13: on\n",
      "14: for\n",
      "15: have\n",
      "16: not\n",
      "17: me\n",
      "18: this\n",
      "19: is\n",
      "20: with\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "reverse_index = {i:t for t, i in word_index.items()}\n",
    "\n",
    "i = 0\n",
    "for t in reverse_index.items():\n",
    "    if i < 20:\n",
    "        print(f\"{t[0]}: {t[1]}\")\n",
    "        i += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Decoding Our Word Vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original complaint text:\n",
      "I have already filed several complaints about AES/PHEAA. I was notified by a XXXX XXXX let @ XXXX, who pretended to be from your office, he said he was from CFPB. I found out this morning he is n't from your office, but is actually works at XXXX. \n",
      "\n",
      "This has wasted weeks of my time. They AES/PHEAA confirmed and admitted ( see attached transcript of XXXX, conversation at XXXX ( XXXX ) with XXXX that proves they verified the loans are not mine ) the student loans they had XXXX, and collected on, and reported negate credit reporting in my name are in fact, not mine. \n",
      "They conclued their investigation on XXXX admitting they made a mistake and have my name on soneone elses loans. I these XXXX loans total {$10000.00}, original amount. My XXXX loans I got was total {$3500.00}. We proved by providing AES/PHEAA, this with my original promissary notes I located recently, the XXXX of my college provided AES/PHEAA with their original shoeinf amounts of my XXXX loans which show different dates and amounts, the dates and amounts are not even close to matching these loans they have in my name, The original lender, XXXX XXXX Bank notifying AES/PHEAA, they never issued me a student loan, and original Loan Guarantor, XXXX, notifying AES/PHEAA, they never were guarantor of my loans. \n",
      "\n",
      "XXXX straight forward. But today, this person, XXXX XXXX, told me they know these loans are not mine, and they refuse to remove my name off these XXXX loan 's and correct their mistake, essentially forcing me to pay these loans off, bucause in XXXX they sold the loans to XXXX loans. \n",
      "\n",
      "This is absurd, first protruding to be this office, and then refusing to correct their mistake. \n",
      "\n",
      "Please for the love of XXXX will soneone from your office call me at XXXX, today. I am a XXXX vet and they are knowingly discriminating against me. \n",
      "Pretending to be you.\n",
      "\n",
      "\n",
      "\n",
      "Decoded review from Tokenizer:\n",
      "i have already filed several complaints about aes i was notified by a xxxx xxxx let xxxx who to be from your office he said he was from cfpb i found out this morning he is n't from your office but is actually works at xxxx this has weeks of my time they aes confirmed and admitted see attached of xxxx conversation at xxxx xxxx with xxxx that they verified the loans are not mine the student loans they had xxxx and on and reported credit reporting in my name are in fact not mine they their investigation on xxxx they made a mistake and have my name on loans i these xxxx loans total 10000 00 original amount my xxxx loans i got was total 00 we by providing aes this with my original notes i located recently the xxxx of my college provided aes with their original amounts of my xxxx loans which show different dates and amounts the dates and amounts are not even close to these loans they have in my name the original lender xxxx xxxx bank notifying aes they never issued me a student loan and original loan xxxx notifying aes they never were of my loans xxxx forward but today this person xxxx xxxx told me they know these loans are not mine and they refuse to remove my name off these xxxx loan 's and correct their mistake essentially me to pay these loans off in xxxx they sold the loans to xxxx loans this is first to be this office and then refusing to correct their mistake please for the of xxxx will from your office call me at xxxx today i am a xxxx and they are against me to be you\n"
     ]
    }
   ],
   "source": [
    "comment_idx_to_preview = 19\n",
    "print('Original complaint text:')\n",
    "print(complaints[comment_idx_to_preview])\n",
    "print('\\n\\n')\n",
    "\n",
    "# The reverse_index cell block above must be complete in order for this cell block to successively execute \n",
    "decoded_review = ' '.join([reverse_index.get(i) for i in sequences[comment_idx_to_preview]])\n",
    "print('Decoded review from Tokenizer:')\n",
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Products to Numerical Categories\n",
    "\n",
    "On to step two of our preprocessing: converting our descriptive categories into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class labels:\n",
      "['Bank account or service', 'Checking or savings account', 'Consumer Loan', 'Credit card', 'Credit reporting', 'Mortgage', 'Student loan']\n",
      "\n",
      "\n",
      "New product labels:\n",
      "[6 6 6 ... 4 4 4]\n",
      "\n",
      "\n",
      "One hot labels; 7 binary columns, one for each of the categories.\n",
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      "\n",
      "One hot labels shape:\n",
      "(60000, 7)\n"
     ]
    }
   ],
   "source": [
    "product = df['Product']\n",
    "\n",
    "# Initialize\n",
    "le = preprocessing.LabelEncoder() \n",
    "le.fit(product)\n",
    "print('Original class labels:')\n",
    "print(list(le.classes_))\n",
    "print('\\n')\n",
    "product_cat = le.transform(product)  \n",
    "\n",
    "# If you wish to retrieve the original descriptive labels post production\n",
    "# list(le.inverse_transform([0, 1, 3, 3, 0, 6, 4])) \n",
    "\n",
    "print('New product labels:')\n",
    "print(product_cat)\n",
    "print('\\n')\n",
    "\n",
    "# Each row will be all zeros except for the category for that observation \n",
    "print('One hot labels; 7 binary columns, one for each of the categories.') \n",
    "product_onehot = to_categorical(product_cat)\n",
    "print(product_onehot)\n",
    "print('\\n')\n",
    "\n",
    "print('One hot labels shape:')\n",
    "print(np.shape(product_onehot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "Now for our final preprocessing step: the usual train-test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test label shape: (1500, 7)\n",
      "Train label shape: (58500, 7)\n",
      "Test shape: (1500, 2000)\n",
      "Train shape: (58500, 2000)\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "test_index = random.sample(range(1,10000), 1500)\n",
    "\n",
    "test = one_hot_results[test_index]\n",
    "train = np.delete(one_hot_results, test_index, 0)\n",
    "\n",
    "label_test = product_onehot[test_index]\n",
    "label_train = np.delete(product_onehot, test_index, 0)\n",
    "\n",
    "print('Test label shape:', np.shape(label_test))\n",
    "print('Train label shape:', np.shape(label_train))\n",
    "print('Test shape:', np.shape(test))\n",
    "print('Train shape:', np.shape(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Let's build a fully connected (Dense) layer network with relu activation in Keras. You can do this using: `Dense(16, activation='relu')`. \n",
    "\n",
    "In this example, use two hidden layers with 50 units in the first layer and 25 in the second, both with a `'relu'` activation function. Because we are dealing with a multiclass problem (classifying the complaints into 7 categories), we use a use a `'softmax'` classifier in order to output 7 class probabilities per case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Two layers with relu activation\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) # \n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "\n",
    "# One layer with softmax activation \n",
    "model.add(layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model\n",
    "\n",
    "Now, compile the model! This time, use `'categorical_crossentropy'` as the loss function and stochastic gradient descent, `'SGD'` as the optimizer. As in the previous lesson, include the accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='SGD',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "In the compiler, you'll be passing the optimizer (SGD = stochastic gradient descent), loss function, and metrics. Train the model for 120 epochs in mini-batches of 256 samples.\n",
    "\n",
    "_Note:_ ⏰ _Your code may take about one to two minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Trains the model for a fixed number of epochs (iterations on a dataset).\n",
       "\n",
       "Arguments:\n",
       "    x: Input data. It could be:\n",
       "      - A Numpy array (or array-like), or a list of arrays\n",
       "        (in case the model has multiple inputs).\n",
       "      - A TensorFlow tensor, or a list of tensors\n",
       "        (in case the model has multiple inputs).\n",
       "      - A dict mapping input names to the corresponding array/tensors,\n",
       "        if the model has named inputs.\n",
       "      - A `tf.data` dataset. Should return a tuple\n",
       "        of either `(inputs, targets)` or\n",
       "        `(inputs, targets, sample_weights)`.\n",
       "      - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
       "        or `(inputs, targets, sample_weights)`.\n",
       "      A more detailed description of unpacking behavior for iterator types\n",
       "      (Dataset, generator, Sequence) is given below.\n",
       "    y: Target data. Like the input data `x`,\n",
       "      it could be either Numpy array(s) or TensorFlow tensor(s).\n",
       "      It should be consistent with `x` (you cannot have Numpy inputs and\n",
       "      tensor targets, or inversely). If `x` is a dataset, generator,\n",
       "      or `keras.utils.Sequence` instance, `y` should\n",
       "      not be specified (since targets will be obtained from `x`).\n",
       "    batch_size: Integer or `None`.\n",
       "        Number of samples per gradient update.\n",
       "        If unspecified, `batch_size` will default to 32.\n",
       "        Do not specify the `batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.Sequence` instances\n",
       "        (since they generate batches).\n",
       "    epochs: Integer. Number of epochs to train the model.\n",
       "        An epoch is an iteration over the entire `x` and `y`\n",
       "        data provided.\n",
       "        Note that in conjunction with `initial_epoch`,\n",
       "        `epochs` is to be understood as \"final epoch\".\n",
       "        The model is not trained for a number of iterations\n",
       "        given by `epochs`, but merely until the epoch\n",
       "        of index `epochs` is reached.\n",
       "    verbose: 0, 1, or 2. Verbosity mode.\n",
       "        0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
       "        Note that the progress bar is not particularly useful when\n",
       "        logged to a file, so verbose=2 is recommended when not running\n",
       "        interactively (eg, in a production environment).\n",
       "    callbacks: List of `keras.callbacks.Callback` instances.\n",
       "        List of callbacks to apply during training.\n",
       "        See `tf.keras.callbacks`.\n",
       "    validation_split: Float between 0 and 1.\n",
       "        Fraction of the training data to be used as validation data.\n",
       "        The model will set apart this fraction of the training data,\n",
       "        will not train on it, and will evaluate\n",
       "        the loss and any model metrics\n",
       "        on this data at the end of each epoch.\n",
       "        The validation data is selected from the last samples\n",
       "        in the `x` and `y` data provided, before shuffling. This argument is\n",
       "        not supported when `x` is a dataset, generator or\n",
       "       `keras.utils.Sequence` instance.\n",
       "    validation_data: Data on which to evaluate\n",
       "        the loss and any model metrics at the end of each epoch.\n",
       "        The model will not be trained on this data. Thus, note the fact\n",
       "        that the validation loss of data provided using `validation_split`\n",
       "        or `validation_data` is not affected by regularization layers like\n",
       "        noise and dropuout.\n",
       "        `validation_data` will override `validation_split`.\n",
       "        `validation_data` could be:\n",
       "          - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
       "          - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
       "          - dataset\n",
       "        For the first two cases, `batch_size` must be provided.\n",
       "        For the last case, `validation_steps` could be provided.\n",
       "        Note that `validation_data` does not support all the data types that\n",
       "        are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
       "    shuffle: Boolean (whether to shuffle the training data\n",
       "        before each epoch) or str (for 'batch'). This argument is ignored\n",
       "        when `x` is a generator. 'batch' is a special option for dealing\n",
       "        with the limitations of HDF5 data; it shuffles in batch-sized\n",
       "        chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
       "    class_weight: Optional dictionary mapping class indices (integers)\n",
       "        to a weight (float) value, used for weighting the loss function\n",
       "        (during training only).\n",
       "        This can be useful to tell the model to\n",
       "        \"pay more attention\" to samples from\n",
       "        an under-represented class.\n",
       "    sample_weight: Optional Numpy array of weights for\n",
       "        the training samples, used for weighting the loss function\n",
       "        (during training only). You can either pass a flat (1D)\n",
       "        Numpy array with the same length as the input samples\n",
       "        (1:1 mapping between weights and samples),\n",
       "        or in the case of temporal data,\n",
       "        you can pass a 2D array with shape\n",
       "        `(samples, sequence_length)`,\n",
       "        to apply a different weight to every timestep of every sample. This\n",
       "        argument is not supported when `x` is a dataset, generator, or\n",
       "       `keras.utils.Sequence` instance, instead provide the sample_weights\n",
       "        as the third element of `x`.\n",
       "    initial_epoch: Integer.\n",
       "        Epoch at which to start training\n",
       "        (useful for resuming a previous training run).\n",
       "    steps_per_epoch: Integer or `None`.\n",
       "        Total number of steps (batches of samples)\n",
       "        before declaring one epoch finished and starting the\n",
       "        next epoch. When training with input tensors such as\n",
       "        TensorFlow data tensors, the default `None` is equal to\n",
       "        the number of samples in your dataset divided by\n",
       "        the batch size, or 1 if that cannot be determined. If x is a\n",
       "        `tf.data` dataset, and 'steps_per_epoch'\n",
       "        is None, the epoch will run until the input dataset is exhausted.\n",
       "        When passing an infinitely repeating dataset, you must specify the\n",
       "        `steps_per_epoch` argument. This argument is not supported with\n",
       "        array inputs.\n",
       "    validation_steps: Only relevant if `validation_data` is provided and\n",
       "        is a `tf.data` dataset. Total number of steps (batches of\n",
       "        samples) to draw before stopping when performing validation\n",
       "        at the end of every epoch. If 'validation_steps' is None, validation\n",
       "        will run until the `validation_data` dataset is exhausted. In the\n",
       "        case of an infinitely repeated dataset, it will run into an\n",
       "        infinite loop. If 'validation_steps' is specified and only part of\n",
       "        the dataset will be consumed, the evaluation will start from the\n",
       "        beginning of the dataset at each epoch. This ensures that the same\n",
       "        validation samples are used every time.\n",
       "    validation_batch_size: Integer or `None`.\n",
       "        Number of samples per validation batch.\n",
       "        If unspecified, will default to `batch_size`.\n",
       "        Do not specify the `validation_batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.Sequence` instances\n",
       "        (since they generate batches).\n",
       "    validation_freq: Only relevant if validation data is provided. Integer\n",
       "        or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
       "        If an integer, specifies how many training epochs to run before a\n",
       "        new validation run is performed, e.g. `validation_freq=2` runs\n",
       "        validation every 2 epochs. If a Container, specifies the epochs on\n",
       "        which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
       "        validation at the end of the 1st, 2nd, and 10th epochs.\n",
       "    max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
       "        input only. Maximum size for the generator queue.\n",
       "        If unspecified, `max_queue_size` will default to 10.\n",
       "    workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
       "        only. Maximum number of processes to spin up\n",
       "        when using process-based threading. If unspecified, `workers`\n",
       "        will default to 1. If 0, will execute the generator on the main\n",
       "        thread.\n",
       "    use_multiprocessing: Boolean. Used for generator or\n",
       "        `keras.utils.Sequence` input only. If `True`, use process-based\n",
       "        threading. If unspecified, `use_multiprocessing` will default to\n",
       "        `False`. Note that because this implementation relies on\n",
       "        multiprocessing, you should not pass non-picklable arguments to\n",
       "        the generator as they can't be passed easily to children processes.\n",
       "\n",
       "Unpacking behavior for iterator-like inputs:\n",
       "    A common pattern is to pass a tf.data.Dataset, generator, or\n",
       "  tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
       "  yield not only features (x) but optionally targets (y) and sample weights.\n",
       "  Keras requires that the output of such iterator-likes be unambiguous. The\n",
       "  iterator should return a tuple of length 1, 2, or 3, where the optional\n",
       "  second and third elements will be used for y and sample_weight\n",
       "  respectively. Any other type provided will be wrapped in a length one\n",
       "  tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
       "  should still adhere to the top-level tuple structure.\n",
       "  e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
       "  features, targets, and weights from the keys of a single dict.\n",
       "    A notable unsupported data type is the namedtuple. The reason is that\n",
       "  it behaves like both an ordered datatype (tuple) and a mapping\n",
       "  datatype (dict). So given a namedtuple of the form:\n",
       "      `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
       "  it is ambiguous whether to reverse the order of the elements when\n",
       "  interpreting the value. Even worse is a tuple of the form:\n",
       "      `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
       "  where it is unclear if the tuple was intended to be unpacked into x, y,\n",
       "  and sample_weight or passed through as a single element to `x`. As a\n",
       "  result the data processing code will simply raise a ValueError if it\n",
       "  encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
       "\n",
       "Returns:\n",
       "    A `History` object. Its `History.history` attribute is\n",
       "    a record of training loss values and metrics values\n",
       "    at successive epochs, as well as validation loss values\n",
       "    and validation metrics values (if applicable).\n",
       "\n",
       "Raises:\n",
       "    RuntimeError: 1. If the model was never compiled or,\n",
       "    2. If `model.fit` is  wrapped in `tf.function`.\n",
       "\n",
       "    ValueError: In case of mismatch between the provided input data\n",
       "        and what the model expects.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.pyenv/versions/anaconda3-2020.02/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 1.8417 - accuracy: 0.2572\n",
      "Epoch 2/120\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 1.5235 - accuracy: 0.4645\n",
      "Epoch 3/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 1.2057 - accuracy: 0.6099\n",
      "Epoch 4/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.9871 - accuracy: 0.6712\n",
      "Epoch 5/120\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.8549 - accuracy: 0.7034\n",
      "Epoch 6/120\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.7747 - accuracy: 0.7239\n",
      "Epoch 7/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.7223 - accuracy: 0.7384\n",
      "Epoch 8/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6851 - accuracy: 0.7478\n",
      "Epoch 9/120\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.6570 - accuracy: 0.7575\n",
      "Epoch 10/120\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.6346 - accuracy: 0.7661\n",
      "Epoch 11/120\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.7731\n",
      "Epoch 12/120\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.6004 - accuracy: 0.7804\n",
      "Epoch 13/120\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.5868 - accuracy: 0.7855\n",
      "Epoch 14/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.5748 - accuracy: 0.7899\n",
      "Epoch 15/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.5640 - accuracy: 0.7946\n",
      "Epoch 16/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.5541 - accuracy: 0.7981\n",
      "Epoch 17/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.5454 - accuracy: 0.8023\n",
      "Epoch 18/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.5370 - accuracy: 0.8054\n",
      "Epoch 19/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.5295 - accuracy: 0.8083\n",
      "Epoch 20/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.5224 - accuracy: 0.8116\n",
      "Epoch 21/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.5158 - accuracy: 0.8135\n",
      "Epoch 22/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.5096 - accuracy: 0.8154\n",
      "Epoch 23/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.5038 - accuracy: 0.8177\n",
      "Epoch 24/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.4986 - accuracy: 0.8198\n",
      "Epoch 25/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.4932 - accuracy: 0.8222\n",
      "Epoch 26/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4885 - accuracy: 0.8246\n",
      "Epoch 27/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.8259\n",
      "Epoch 28/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4794 - accuracy: 0.8276\n",
      "Epoch 29/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.4753 - accuracy: 0.8289\n",
      "Epoch 30/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.4714 - accuracy: 0.8306\n",
      "Epoch 31/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.4676 - accuracy: 0.8327\n",
      "Epoch 32/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.4640 - accuracy: 0.8341: 0s - loss: 0.464\n",
      "Epoch 33/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.4604 - accuracy: 0.8351\n",
      "Epoch 34/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.4572 - accuracy: 0.8359\n",
      "Epoch 35/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4538 - accuracy: 0.8380\n",
      "Epoch 36/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4507 - accuracy: 0.8387\n",
      "Epoch 37/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4477 - accuracy: 0.8398\n",
      "Epoch 38/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4446 - accuracy: 0.8410\n",
      "Epoch 39/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4420 - accuracy: 0.8422\n",
      "Epoch 40/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4393 - accuracy: 0.8435\n",
      "Epoch 41/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4364 - accuracy: 0.8436\n",
      "Epoch 42/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4343 - accuracy: 0.8445\n",
      "Epoch 43/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4319 - accuracy: 0.8455\n",
      "Epoch 44/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4292 - accuracy: 0.8458\n",
      "Epoch 45/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4269 - accuracy: 0.8472\n",
      "Epoch 46/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4248 - accuracy: 0.8481\n",
      "Epoch 47/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4228 - accuracy: 0.8495\n",
      "Epoch 48/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4205 - accuracy: 0.8505\n",
      "Epoch 49/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4182 - accuracy: 0.8513\n",
      "Epoch 50/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4162 - accuracy: 0.8514\n",
      "Epoch 51/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4144 - accuracy: 0.8520\n",
      "Epoch 52/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4123 - accuracy: 0.8524\n",
      "Epoch 53/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4104 - accuracy: 0.8535\n",
      "Epoch 54/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4083 - accuracy: 0.8534\n",
      "Epoch 55/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4068 - accuracy: 0.8542\n",
      "Epoch 56/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4049 - accuracy: 0.8556\n",
      "Epoch 57/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4033 - accuracy: 0.8563\n",
      "Epoch 58/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.4014 - accuracy: 0.8564: 0s - los\n",
      "Epoch 59/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3996 - accuracy: 0.8576\n",
      "Epoch 60/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3983 - accuracy: 0.8579\n",
      "Epoch 61/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3963 - accuracy: 0.8585\n",
      "Epoch 62/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3945 - accuracy: 0.8593\n",
      "Epoch 63/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3931 - accuracy: 0.8600\n",
      "Epoch 64/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3918 - accuracy: 0.8606\n",
      "Epoch 65/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3904 - accuracy: 0.8608\n",
      "Epoch 66/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3886 - accuracy: 0.8619\n",
      "Epoch 67/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3870 - accuracy: 0.8617\n",
      "Epoch 68/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3860 - accuracy: 0.8626\n",
      "Epoch 69/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3842 - accuracy: 0.8628\n",
      "Epoch 70/120\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.3829 - accuracy: 0.8634\n",
      "Epoch 71/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3815 - accuracy: 0.8637\n",
      "Epoch 72/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3801 - accuracy: 0.8644\n",
      "Epoch 73/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3785 - accuracy: 0.8647\n",
      "Epoch 74/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3773 - accuracy: 0.8658\n",
      "Epoch 75/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8658\n",
      "Epoch 76/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8668\n",
      "Epoch 77/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3736 - accuracy: 0.8668\n",
      "Epoch 78/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3720 - accuracy: 0.8679\n",
      "Epoch 79/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3710 - accuracy: 0.8685\n",
      "Epoch 80/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3696 - accuracy: 0.8685\n",
      "Epoch 81/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3681 - accuracy: 0.8689\n",
      "Epoch 82/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3669 - accuracy: 0.8689\n",
      "Epoch 83/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3660 - accuracy: 0.8692\n",
      "Epoch 84/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3646 - accuracy: 0.8701\n",
      "Epoch 85/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3633 - accuracy: 0.8713\n",
      "Epoch 86/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3623 - accuracy: 0.8715\n",
      "Epoch 87/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3614 - accuracy: 0.8709\n",
      "Epoch 88/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3599 - accuracy: 0.8718\n",
      "Epoch 89/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3585 - accuracy: 0.8725\n",
      "Epoch 90/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3579 - accuracy: 0.8730\n",
      "Epoch 91/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3564 - accuracy: 0.8736\n",
      "Epoch 92/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3551 - accuracy: 0.8741\n",
      "Epoch 93/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3542 - accuracy: 0.8737\n",
      "Epoch 94/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3531 - accuracy: 0.8747\n",
      "Epoch 95/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3518 - accuracy: 0.8754\n",
      "Epoch 96/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3508 - accuracy: 0.8755\n",
      "Epoch 97/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3496 - accuracy: 0.8757\n",
      "Epoch 98/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3483 - accuracy: 0.8758\n",
      "Epoch 99/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3473 - accuracy: 0.8769\n",
      "Epoch 100/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3463 - accuracy: 0.8775\n",
      "Epoch 101/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3451 - accuracy: 0.8776\n",
      "Epoch 102/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3443 - accuracy: 0.8785\n",
      "Epoch 103/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3430 - accuracy: 0.8778\n",
      "Epoch 104/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3418 - accuracy: 0.8787\n",
      "Epoch 105/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3408 - accuracy: 0.8794\n",
      "Epoch 106/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3397 - accuracy: 0.8795\n",
      "Epoch 107/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3390 - accuracy: 0.8794\n",
      "Epoch 108/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3379 - accuracy: 0.8804\n",
      "Epoch 109/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3366 - accuracy: 0.8805\n",
      "Epoch 110/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8805\n",
      "Epoch 111/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3344 - accuracy: 0.8816\n",
      "Epoch 112/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3334 - accuracy: 0.8815\n",
      "Epoch 113/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3326 - accuracy: 0.8825\n",
      "Epoch 114/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3315 - accuracy: 0.8829\n",
      "Epoch 115/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3303 - accuracy: 0.8832\n",
      "Epoch 116/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3288 - accuracy: 0.8831\n",
      "Epoch 117/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3282 - accuracy: 0.8846\n",
      "Epoch 118/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3268 - accuracy: 0.8844\n",
      "Epoch 119/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3258 - accuracy: 0.8848\n",
      "Epoch 120/120\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3251 - accuracy: 0.8843\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "history = model.fit(\n",
    "    x=train,\n",
    "    y=label_train,\n",
    "    epochs=120,\n",
    "    batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the dictionary `history` has two entries: the loss and the accuracy achieved using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results\n",
    "\n",
    "As you might expect, we'll use our `matplotlib` for graphing. Use the data stored in the `history_dict` above to plot the loss vs epochs and the accuracy vs epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss vs the number of epoch\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "y_loss = history_dict['loss']\n",
    "x_epoch = list(range(1,len(y_loss)+1))\n",
    "plt.plot(x_epoch, y_loss)\n",
    "plt.xlabel('$|epochs|$')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training accuracy vs the number of epochs\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "y_acc = history_dict['accuracy']\n",
    "x_epoch = list(range(1,len(y_acc)+1))\n",
    "plt.plot(x_epoch, y_acc)\n",
    "plt.xlabel('$|epochs|$')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like we could just keep on going and accuracy would go up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "Finally, it's time to make predictions. Use the relevant method discussed in the previous lesson to output (probability) predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output (probability) predictions for the test set \n",
    "y_hat_test = model.predict(test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance\n",
    "\n",
    "Finally, print the loss and accuracy for both the train and test sets of the final trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829/1829 [==============================] - 2s 826us/step - loss: 0.3183 - accuracy: 0.8886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3182646930217743, 0.888649582862854]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the loss and accuracy for the training set \n",
    "results_train = model.evaluate(train, label_train)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25741079449653625, 0.9246666431427002]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the loss and accuracy for the test set \n",
    "results_test = model.evaluate(test, label_test)\n",
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the training set results are really good, but the test set results lag behind. We'll talk a little more about this in the next lesson, and discuss how we can get better test set results as well!\n",
    "\n",
    "\n",
    "## Additional Resources \n",
    "\n",
    "- https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb \n",
    "- https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "## Summary \n",
    "\n",
    "Congratulations! In this lab, you built a neural network thanks to the tools provided by Keras! In upcoming lessons and labs we'll continue to investigate further ideas regarding how to tune and refine these models for increased accuracy and performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda: learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
